# Sentiment Classification with RNN, LSTM and GRU
## 簡介
在美妝或保養品產業中，品牌方通常需要等到產品上市後，才能從使用者評論中獲得回饋，進而改良產品或調整行銷策略。然而，這樣的「事後補救」對企業而言往往成本高、風險大。若能預先從類似產品的評論中提取常見優缺點，並用於評估新產品的潛在反應，將有助於企業在產品開發階段進行調整，降低風險並強化市場策略。

從生產者角度出發，建立模型，利用過去評論歸納產品的優缺點，再根據該產品的成分、分類與特色標籤等資訊（作為輸入的特徵），預測新品可能會引發的使用者回饋類型（如「太油膩」、「容易過敏」、「保濕力佳」等）。與傳統推薦系統不同，本專案著重於「事前預測」產品的潛在評價類型，協助生產者在產品尚未上市前做出更有策略性的開發與行銷決策。

## 資料敘述
資料來源為公開資料集「Sephora Products and Skincare Reviews」，由 Kaggle 使用者 NADY INKY 整理提供。資料於 2023 年 3 月透過 Python 爬蟲自 Sephora 官方網站擷取，包含超過 8,000 筆產品資訊與約 100 萬則使用者評論。產品資訊涵蓋名稱、品牌、成分、價格及多層級分類；評論則包含用戶評分、推薦意見及完整文字內容，資料完整且豐富，適合用於產品優缺點分析與預測。

表一、產品資訊變數說明

| 變數名稱             | 說明                                         |
|-------------------|--------------------------------------------|
| product_id        | 產品的唯一識別碼                              |
| product_name      | 產品的完整名稱                                |
| brand_id          | 品牌的唯一識別碼                              |
| brand_name        | 品牌的完整名稱                                |
| loves_count       | 將此產品標記為最愛的人數                       |
| rating            | 根據用戶評論計算的產品平均評分                  |
| reviews           | 該產品的使用者評論數量                         |
| size              | 產品容量                                     |
| variation_type    | 產品的變化類型（例如：尺寸、顏色）              |
| variation_value   | 產品變化的具體數值（例如：100 mL）             |
| variation_desc    | 變化參數的說明（例如：最白皙膚色的色調）        |
| ingredients       | 成分列表                                     |
| price_usd         | 產品的美金價格                                |
| value_price_usd   | 顯示於網站上產品可能節省的費用                  |
| sale_price_usd    | 折扣後的美金價格                              |
| limited_edition   | 是否為限量商品（1表示是，0表示否）              |
| new               | 是否為新品（1表示是，0表示否）                  |
| online_only       | 是否僅限網路販售（1表示是，0表示否）            |
| out_of_stock      | 是否已售完（1表示是，0表示否）                  |
| sephora_exclusive | 是否為Sephora獨家商品（1表示是，0表示否）        |
| highlights        | 產品特色的標籤清單                            |
| primary_category  | 產品分類的第一層級                             |
| secondary_category| 產品分類的第二層級                             |
| tertiary_category | 產品分類的第三層級                             |
| child_count       | 產品可選變化版本的數量                         |
| child_max_price   | 所有變化版本中的最高價格                       |
| child_min_price   | 所有變化版本中的最低價格                       |


表二、使用者評論變數說明

| 變數名稱                 | 說明                                             |
|----------------------|------------------------------------------------|
| author_id            | 評論者的唯一識別碼                                  |
| rating               | 評論者對產品的評分                                   |
| is_recommended       | 是否推薦此產品（1為推薦，0為不推薦）                    |
| helpfulness          | 評論的有幫助程度（正面評價數 / 總評價數）               |
| total_feedback_count | 該評論被其他用戶評價的總次數（正評 + 負評）             |
| total_neg_feedback_count | 該評論獲得的負面評價次數                         |
| total_pos_feedback_count | 該評論獲得的正面評價次數                         |
| submission_time      | 評論的提交日期（格式為 yyyy-mm-dd）                   |
| review_text          | 使用者撰寫的完整評論內容                               |
| review_title         | 評論的標題                                        |
| skin_tone            | 評論者的膚色                                       |
| eye_color            | 評論者的眼睛顏色                                    |
| skin_type            | 評論者的膚質類型                                    |
| hair_color           | 評論者的髮色                                       |
| product_id           | 產品的唯一識別碼                                    |
| product_name         | 產品的完整名稱                                      |
| brand_name           | 品牌的完整名稱                                      |
| price_usd            | 產品的美金價格                                      |

## 分析過程
一、 原始資料處理

首先，針對產品資料（product_info）進行欄位篩選，保留與產品成分與分類相關的欄位，包括product_id、product_name、ingredients、highlights、primary_category、secondary_category與tertiary_category，作為後續模型的輸入特徵X。為降低資料雜訊，將移除product_id、product_name、ingredients、highlights欄位的缺失值與重複的資料列。

評論資料部分，分別來自五個不同長度的子檔（reviews_0-250、reviews_250-500、reviews_500-750、reviews_750-1250、reviews_1250-end），讀入後統一保留三個欄位：review_text、is_recommended、product_id。同樣進行缺失值與重複資料清理後，根據is_recommended欄位作為正面及負面評論的分類依據，其中1表示推薦（視為正面評論），0表示不推薦（視為負面評論）。

為處理正面與負面評論中的多標籤分類問題，本專案採用評論文本進行自動主題選取，也就是根據評論內容本身歸納出有哪些主題，而非事先預設主題類別。具體流程如下，先利用TF-IDF模型對每則評論進行統計編碼，挑選出高頻關鍵詞（最多保留1,000個）。其中，出現在超過70%文本中的常見詞因缺乏鑑別力而被排除；同時，出現次數少於5次的低頻詞也一併濾除。接著，從TF-IDF分數最高的前300個關鍵詞中，透過預訓練語意模型Sentence-BERT（本專案使用all-MiniLM-L6-v2）將這些詞彙轉換為語意嵌入向量，用以捕捉詞與詞之間的語意關聯。之後，把語意嵌入向量輸入KMeans演算法進行高頻詞分群（群數設定為10），以自動區分出語意接近的詞彙群組。再經人工檢視每一群中具代表性的詞彙，並定義其所對應的主題面向。根據語義分析結果，正面與負面評論各自產生多個主題群。例如，在正面評論中，包含soft、glow、smooth的詞群被歸類為「Texture & Radiant Skin」；包含moisturize、hydrating、gentle的詞群則歸入「Moisturizing & Gentle」。在負面評論中，dry、sticky、greasy等詞則被歸類為「Texture and Hydration Problems」；acne、sensitive skin、oily skin等則對應「Skin Type Sensitivity」主題。以下為主題標籤的分群結果：

(一) 正面標籤主題分類：
* Cluster 0：「Texture & Radiant Skin」，質地與使肌膚光澤。
* Cluster 1：「Moisturizing & Gentle」，保濕且溫和。
* Cluster 2：「Strong Recommendation」，強烈推薦。

(二) 負面標籤主題分類：
* Cluster 0：「No Visible Change」，看不出變化。
* Cluster 1：「Scent」，氣味問題。
* Cluster 2：「Ineffectiveness」，效果不佳。
* Cluster 3：「Specific Area or Routine Issues」，特定部位或使用問題。
* Cluster 4：「Texture and Hydration Problems」，質地或保濕問題。
* Cluster 5：「Skin Type Sensitivity」，膚質敏感問題。

建立主題後，為了提升實際評論中的標記準確率，本專案進一步將所有主題中的關鍵詞與評論文本進行詞幹化（Stemming）處理，以統一詞形變化並提升比對彈性。將每個關鍵詞片語轉為小寫後詞幹化，建構出詞幹對應標籤的映射字典（stemmed_map）；同時對每篇評論文本進行相同的詞幹化處理，並將其中出現的詞幹片語與映射字典進行比對。若評論中出現某詞幹化後的關鍵詞，則標記為該關鍵詞的主題。由於評論可能涵蓋多個主題，此為一個多標籤分類任務（multi-label classification）。若某些評論無法歸類至任何主題，則視為無標籤資料並予以移除。

然而，由於同一產品可能有多筆評論，每則評論所關注的主題可能不同，導致相同產品資訊（輸入特徵）對應到多種主題組合（輸出結果），使模型難以學習對應關係。為解決此問題，先收集每個產品的各項主題次數，轉換為該產品整體被提及的主題集合，但避免大多數產品被標記成涵蓋所有主題，導致預測無區別性，正面回饋評論僅保留該產品中出現頻率最高的前兩個主題，且要求其在該產品所有評論中的出現頻率須達20%以上；負面評論則取前三高頻主題，且主題的出現比例須達10%以上。將篩選後的結果再次去除無標籤資料，與產品資訊透過product_id進行合併，作為建模的資料集。本專案分別整理兩組資料集：正面資料集（共1,857筆，選其中1,480筆為訓練集，370筆為測試集）可用於後續行銷策略的分析；負面資料集（共1,758筆，選其中1,400筆為訓練集，350筆為測試集）則可作為產品改良的參考。

連接產品資料的ingredients、highlights以及三個分類欄位（primary、secondary、tertiary）字串作為單一文本輸入，並將每筆樣本的最大長度設為256，對不足部分進行padding（補零），超出則截斷。文字編碼部分，使用Tokenizer對訓練資料建立詞彙表，僅保留最常出現的5,000個詞，並將每段文字轉換為對應的詞ID序列。

標籤則透過MultiLabelBinarizer將原為list結構的多標籤資料轉換為multi-hot向量，用於多標籤分類模型。由於每個標籤可獨立存在，多標籤分類本質上可視為多個二元分類子任務，故模型輸出層需使用sigmoid函數，以預測每一類別的出現機率。例如當用於預測正面主題的模型對某項產品輸出[0.3, 0.8, 0.77]時，表示該產品較可能引發與類別1和類別2相關的正面回饋。

接下來對輸入的產品資料字串進行語意編碼，本專案初期曾嘗試用GloVe詞向量，但因詞彙涵蓋率偏低（約40%），整體模型表現未如預期。主要是因為美妝保養品的成分名稱多為專有名詞，GloVe對此類詞彙的覆蓋率與語意表達能力有限，導致模型效果不佳。為改善此問題，改用Fasttext的預訓練詞向量（每個詞對應300維向量）。Fasttext能夠透過子詞結構捕捉詞彙的形態資訊，即使是訓練資料中未出現的新詞，也能推估其語意，較適合用於含有大量專業用語的文本。接著，構建詞彙與Fasttext向量的對應字典embeddings_index。再由先前Tokenizer建立的詞彙表，隨後生成embedding_matrix，將出現在資料中的詞彙轉換為對應的詞向量。

最後，將此embedding_matrix作為初始權重，組成模型的Embedding層，並設定trainable = True，使詞向量在訓練過程中可進行微調，以適應任務語意並提升模型表現。

二、 模型設計與比較

本專案對正面與負面資料皆採用一致的模型設計，建立三種循環神經網路進行比較，分別為基本RNN、雙向LSTM與雙向GRU。為確保模型具有可比性，三者均採相同的分析結構：

(一) 模型結構

* 嵌入層（Embedding Layer）：使用微調後的Fasttext詞向量，將每個詞轉換為固定維度的向量表示。
* 單層循環神經單元（RNN / 雙向LSTM / 雙向GRU）：隱藏層單元數皆設為32。
* 輸出層：使用Sigmoid作為激活函數對應多標籤分類任務，每個類別獨立進行二元分類。

(二) 模型訓練與評估

訓練過程中，以驗證集損失（val_loss）最小的epoch作為模型參數。進行後續模型評估前，需先說明混淆矩陣的定義。混淆矩陣是由預測與實際結果交叉組成的四種情況，分別為：
-	True Positive (TP)：實際是正樣本，且預測為正樣本。
-	False Positive (FP)：實際是負樣本，但誤判為正樣本。
-	False Negative (FN)：實際是正樣本，但誤判為負樣本。
-	True Negative (TN)：實際是負樣本，且預測為負樣本。

根據上述四種情況，可進一步計算以下評估指標：
* Percision = TP / (TP+FP)，預測為正樣本中，實際正確的比例。
* Recall = TP / (TP+FN)，所有實際正樣本中，被正確預測的比例。
* BinaryAccuracy = mean[(TP+TN) / (TP+FP+FN+TN)]，對每個類別分別計算準確率後取平均。
* F1 Score = 2 * Precision * Recall / (Precision + Recall)，同時考量Precision和Recall的綜合指標。

針對多標籤任務，F1分數可分為兩種計算方式：
1. Micro-F1：合併所有標籤的TP、FP、FN再計算F1，適合資料不平衡時衡量整體表現。數值介於0到1，越接近1表示整體預測越準確。
2. Macro-F1：分別計算每一標籤的F1，再取平均，衡量模型對所有類別的平均能力。數值介於0到1，越接近1表示模型在各類別都有不錯的預測表現，沒有特別偏向某一類。

由於正面與負面主題中的各類別標籤分布不均，因此在比較三種模型時，採用Micro-F1作為主要評估指標。根據Micro-F1選出最佳模型後，進行兩個改善過度擬合的方法：
* L1正規化：在循環神經單元後加L1懲罰項，使部分權重收斂為0。
* Dropout：在循環神經單元後新增Dropout層，隨機丟棄50%節點。



## 結論
一、 正面資料

在正面資料中，三種單層循環神經網路模型皆有傾向將產品分類為類別1或2的現象，顯示資料本身存在類別不平衡的情況。其中，以GRU為核心的模型在Testing micro分數上表現最佳，約為0.848，代表其在整體預測較為準確。進一步針對GRU模型加入L1正規化與Dropout以減緩過度擬合問題，但整體結果未優於原始GRU模型。雖然加入L1正規化的模型在驗證階段（val_loss）有下降，最終測試表現仍略低於原始版本。

從語意分析結果可看出，消費者對保養品的正面回饋多集中於「保濕效果」、「溫和性」以及「願意推薦他人」等特徵，顯示這些因素在消費者心中佔有高度地位。因此，品牌在行銷策略上可著重於強調產品的保濕與溫和功效，並針對肌膚較乾燥的族群進行推廣，同時可透過小樣贈品鼓勵顧客分享，提升產品的自然曝光。

二、 負面資料

負面資料中，同樣觀察到明顯的分類不平衡現象，其中以RNN模型在Testing micro分數上表現最佳，約為0.790，表示整體預測能力較穩定。針對過度擬合問題，加入L1正規化與Dropout機制後，可發現兩者皆有助於降低過度擬合的情況，而L1正規化的成效最佳，約為0.796。

在負面標籤主題分類方面，模型預測結果多集中於「氣味問題」、「特定部位或使用問題」以及「質地或保濕問題」等類別，顯示這些面向是消費者最常提出的負面回饋。針對這些反應，品牌方可調整相關產品原料或成分配方；同時也可考慮在產品說明中明確標示適用族群與使用建議，以降低使用者不適的可能性。
